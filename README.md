# LipSync-Listed
This project is based on Wav2Lip-GFPGAN, but updates the requirements.txt (to function properly) and updates Colab file for ease of use.

## Steps to run

2. Open the **Wav2Lipsync.ipynb** file in your google colab

3. Connect your colab notebook to the runtime and run the first section ***Setting up.***

4. Upload your audio and video to the `/content/wav2lip-HD/inputs` directory.
  
5. Enter the file names (not file path) in the cell under ***Providing inputs and running the Model*** section and choose your Wav2Lip model. 

6. Run all the below cells upto but not ***Running this will empty /inputs and /outputs, so you can start again, fresh*** section. 

7. Now clear the input/output if needed.
